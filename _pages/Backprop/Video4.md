---
layout: module
permalink: /Backprop/Video4
title: "CS 477: Micrograd: A General Backprop Engine"
excerpt: "CS 477: Micrograd: A General Backprop Engine"

info:
  prev: "./Video3"
  comments: "true"
---

<p>
Watch the video below, which was made by Andrej Karpathy (formerly OpenAI and lead of Tesla AI).  He goes into an even more generalized version of backpropagation in python for any configuration of neurons (not necessarily fully connected, as with MLPs).  He calls his system "micrograd."  This will be slower than the specialized matrix formulation we made for MLPs, but it's need to see everything in its full generality, and Andrej uses a lot of awesome syntactic sugar in python to make it very intuitive.  The video is <b>long</b> (~2 hours), but it will be worth it.  When you're finished watching it, answer the questions at <a href = "https://ursinus.instructure.com/courses/16260/assignments/189691">this link</a>.
</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/VMj-3S1tku0?si=rbuPMsi_Otnjectp" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

<h2>Notes</h2>

